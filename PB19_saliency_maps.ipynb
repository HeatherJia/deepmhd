{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knGDutJKrkvV"
   },
   "source": [
    "#### Adapted from \"Attention on MNIST (Saliency and grad-CAM)\" from the keras-vis package\n",
    "\n",
    "https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jegpeek/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from vis.visualization import visualize_saliency\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained model. Here were are looking at the model trained on data that have not had the fixed fourier power applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model_path = get_file('DLfile.dms','https://www.dropbox.com/s/46z20173319zicv/model2_128_4.dms?dl=0')\n",
    "#load_model(model_path)\n",
    "model = load_model('model2_128_4.dms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows = 128\n",
    "img_cols = 128\n",
    "\n",
    "#loading test (non-FFP) data:\n",
    "test_x_b1 = np.load('b1p.01XY_test_ss1_sh_64_ims_128.npy')\n",
    "test_x_b01 = np.load('b.1p.01XY_test_ss1_sh_64_ims_128.npy')\n",
    "\n",
    "teshape = test_x_b1.shape\n",
    "\n",
    "x_test = np.zeros([teshape[2]*2, img_rows, img_rows])\n",
    "x_test[::2, :, :] = np.transpose(test_x_b01)\n",
    "x_test[1::2, :, :] = np.transpose(test_x_b1)\n",
    "\n",
    "y_test = np.zeros([teshape[2]*2])\n",
    "y_test[::2] = np.zeros([teshape[2]])\n",
    "y_test[1::2] = np.ones([teshape[2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For saliency to work properly the last layer needs to be linear, not softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "XYzt8Op7rkvj",
    "outputId": "f447330f-5f82-4d4a-a6ad-3ea36fba404c"
   },
   "outputs": [],
   "source": [
    "layer_idx = utils.find_layer_idx(model, \"preds\")\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|----------| 0/18   0% [elapsed: 00:00 left: ?, ? iters/sec]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jegpeek/anaconda3/lib/python3.5/site-packages/matplotlib/contour.py:1180: UserWarning: No contour levels were found within the data range.\n",
      "  warnings.warn(\"No contour levels were found\"\n",
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "low_am = 1\n",
    "label=''\n",
    "if low_am == 1:\n",
    "    label = '_low_AM'\n",
    "plt.figure(figsize=[16, 16])\n",
    "# just to get these sorted by columns, not rows\n",
    "colsfirst = np.reshape(np.arange(36), [6, 6]).T.flatten()\n",
    "for i in tqdm(np.arange(18)):\n",
    "    idx = i*2+1\n",
    "    class_idx =1\n",
    "    plt.subplot(6,6,colsfirst[i]+1)\n",
    "    grads = visualize_saliency(model, layer_idx, filter_indices=class_idx, seed_input=(x_test[idx])[:, :, None], backprop_modifier='guided')\n",
    "    plt.imshow(x_test[idx][...], cmap='gray')\n",
    "    # filtering here smooths out some of the substructure caused by CNN architecture\n",
    "    gfilt = gaussian_filter(np.sum(grads, axis=2), 1.0)\n",
    "    plt.contour(gfilt, cmap='bwr_r', levels=[200], linewidths=1)\n",
    "    #plt.imshow(masked_gfilt, cmap='plasma')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "for i in tqdm(np.arange(18,36)):\n",
    "    idx = i*2\n",
    "    class_idx =0\n",
    "    plt.subplot(6,6,colsfirst[i]+1)\n",
    "    grads = visualize_saliency(model, layer_idx, filter_indices=class_idx, seed_input=(x_test[idx])[:, :, None], backprop_modifier='guided')\n",
    "    plt.imshow(x_test[idx][...], cmap='gray')\n",
    "    # filtering here smooths out some of the substructure caused by CNN architecture\n",
    "    gfilt = gaussian_filter(np.sum(grads, axis=2), 1.0)\n",
    "    plt.contour(gfilt, cmap='bwr_r', levels=[200], linewidths=1)\n",
    "    #plt.imshow(masked_gfilt, cmap='plasma')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.savefig('Saliency_both.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "Playing with attention and saliency.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
